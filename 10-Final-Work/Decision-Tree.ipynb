{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import read_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "type(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 9\n",
    "TRAIN_FILE_PATH = \"./asset/training_data.txt\"\n",
    "\n",
    "VOWELS_TABLE = \"\"\"\\\n",
    "|   AA  |   ɑ   |\n",
    "|   AE  |   æ   |\n",
    "|   AH  |   ʌ   |\n",
    "|   AO  |   ɔ   |\n",
    "|   AW  |   aʊ  |\n",
    "|   AY  |   aɪ  |\n",
    "|   EH  |   ɛ   |\n",
    "|   ER  |   ɜːr |\n",
    "|   EY  |   eɪ  |\n",
    "|   IH  |   ɪ   |\n",
    "|   IY  |   i   |\n",
    "|   OW  |   oʊ  |\n",
    "|   OY  |   ɔɪ  |\n",
    "|   UH  |   ʊ   |\n",
    "|   UW  |   u   |\n",
    "\"\"\"\n",
    "\n",
    "CONSONANT_TABLE = \"\"\"\\\n",
    "|     P     |  p  |\n",
    "|     S     |  s  |\n",
    "|     B     |  b  |\n",
    "|     SH    |  ʃ  |\n",
    "|     CH    |  tʃ |\n",
    "|     T     |  t  |\n",
    "|     D     |  d  |\n",
    "|     TH    |  θ  |\n",
    "|     DH    |  ð  |\n",
    "|     V     |  v  |\n",
    "|     F     |  f  |\n",
    "|     W     |  w  |\n",
    "|     G     |  g  |\n",
    "|     Y     |  j  |\n",
    "|     HH    |  h  |\n",
    "|     Z     |  z  |\n",
    "|     JH    |  dʒ |\n",
    "|     ZH    |  ʒ  |\n",
    "|     K     |  k  |\n",
    "|     L     |  l  |\n",
    "|     M     |  m  |\n",
    "|     N     |  n  |\n",
    "|     NG    |  ŋ  |\n",
    "|     R     |  r  |\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_phonemes(phonemes_table):\n",
    "    ans = {}\n",
    "    phonemes_list = list(filter(lambda x: not x in \"\\n\",\n",
    "                              phonemes_table.replace(\" \", \"\").split(\"|\")))\n",
    "    for x in range(0, len(phonemes_list), 2):\n",
    "        ans[phonemes_list[x]] =  phonemes_list[x+1]\n",
    "    return ans\n",
    "\n",
    "train_data = read_data(TRAIN_FILE_PATH)\n",
    "\n",
    "vowels_dict = init_phonemes(VOWELS_TABLE)\n",
    "consonants_dict = init_phonemes(CONSONANT_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contain_phonemes(phoneme, phonemes_dict):\n",
    "    return phoneme in phonemes_dict\n",
    "\n",
    "def count_contain_phonemes_num(phonemes_list, phonemes_dict):\n",
    "    return len(list(filter(lambda phoneme:contain_phonemes(phoneme, phonemes_dict), phonemes_list)))\n",
    "\n",
    "def get_world(line):\n",
    "    return line.split(\":\")[0]\n",
    "\n",
    "def has_number(string):\n",
    "    return any(char.isdigit() for char in string)\n",
    "\n",
    "def get_stress_index(vowels_list):\n",
    "    return [i + 1 for i, x in enumerate(vowels_list) if \"1\" in x][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(line):\n",
    "    line = line.split(\":\")[1]\n",
    "    phonemes_list = line.split(\" \")\n",
    "    vowels_list = list(filter(lambda phoneme: has_number(phoneme), phonemes_list))\n",
    "    consonants_list = list(filter(lambda phoneme: not has_number(phoneme), phonemes_list))\n",
    "    # print(count_contain_phonemes_num(constants_list, consonants_dict))\n",
    "    \n",
    "    vowels_vector = list(vowels_dict)\n",
    "    for i in range(len(vowels_vector)):\n",
    "        vowels_vector[i] = 1 if vowels_vector[i] in [vowel[0:2] for vowel in vowels_list] else 0\n",
    "        \n",
    "    consonants_vector = list(consonants_dict)\n",
    "    for i in range(len(consonants_vector)):\n",
    "        consonants_vector[i] = 1 if consonants_vector[i] in consonants_list else 0\n",
    "        \n",
    "    return [get_stress_index(vowels_list), len(vowels_list), len(consonants_list)] + vowels_vector + consonants_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_index</th>\n",
       "      <th>vowels_size</th>\n",
       "      <th>constans_size</th>\n",
       "      <th>AA</th>\n",
       "      <th>AE</th>\n",
       "      <th>AH</th>\n",
       "      <th>AO</th>\n",
       "      <th>AW</th>\n",
       "      <th>AY</th>\n",
       "      <th>EH</th>\n",
       "      <th>...</th>\n",
       "      <th>HH</th>\n",
       "      <th>Z</th>\n",
       "      <th>JH</th>\n",
       "      <th>ZH</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>NG</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COED</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURVIEW</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEHIR</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUSCLING</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONPOISONOUS</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stress_index  vowels_size  constans_size  AA  AE  AH  AO  AW  \\\n",
       "COED                     1            2              2   0   0   0   0   0   \n",
       "PURVIEW                  1            2              3   0   0   0   0   0   \n",
       "HEHIR                    1            2              3   0   0   0   0   0   \n",
       "MUSCLING                 1            3              4   0   0   1   0   0   \n",
       "NONPOISONOUS             2            4              6   1   0   1   0   0   \n",
       "\n",
       "              AY  EH ...  HH  Z  JH  ZH  K  L  M  N  NG  R  \n",
       "COED           0   1 ...   0  0   0   0  1  0  0  0   0  0  \n",
       "PURVIEW        0   0 ...   0  0   0   0  0  0  0  0   0  0  \n",
       "HEHIR          0   1 ...   1  0   0   0  0  0  0  0   0  1  \n",
       "MUSCLING       0   0 ...   0  0   0   0  0  1  1  0   1  0  \n",
       "NONPOISONOUS   0   0 ...   0  1   0   0  0  0  0  1   0  0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([get_data(line) for line in train_data], \n",
    "                  index=[get_world(line) for line in train_data],\n",
    "                  columns=[\"stress_index\", \"vowels_size\", \"constans_size\"] + list(vowels_dict) + list(consonants_dict))\n",
    "df.head()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stress_index',\n",
       " 'vowels_size',\n",
       " 'constans_size',\n",
       " 'IY',\n",
       " 'AA',\n",
       " 'OW',\n",
       " 'AH',\n",
       " 'N',\n",
       " 'EH',\n",
       " 'SH',\n",
       " 'V',\n",
       " 'K',\n",
       " 'UW',\n",
       " 'R',\n",
       " 'P',\n",
       " 'IH',\n",
       " 'EY',\n",
       " 'M',\n",
       " 'T',\n",
       " 'Y',\n",
       " 'S',\n",
       " 'D',\n",
       " 'ZH',\n",
       " 'JH',\n",
       " 'CH',\n",
       " 'AO',\n",
       " 'Z',\n",
       " 'OY',\n",
       " 'F',\n",
       " 'L',\n",
       " 'UH',\n",
       " 'TH',\n",
       " 'DH',\n",
       " 'AE',\n",
       " 'G',\n",
       " 'AY',\n",
       " 'AW',\n",
       " 'B',\n",
       " 'NG',\n",
       " 'W',\n",
       " 'HH',\n",
       " 'ER']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[(df[\"vowels_size\"] == 1) | (df[\"vowels_size\"] == 5)].size\n",
    "\n",
    "# df.groupby(['vowels_size', 'stress_index']).agg(\n",
    "#     {'constans_size':'count'}).groupby(level=0).apply(lambda x : \n",
    "# x * 100 / float(x.sum())).add_suffix('_Count').reset_index().columns[1]\n",
    "\n",
    "# df.groupby(['vowels_size', 'stress_index']).agg(\n",
    "#     {'constans_size':'count'}).groupby(level=0).apply(lambda x :                          \n",
    "#                                                       x * 100 / float(x.sum())).groupby(\"vowels_size\").plot.pie(subplots=True)\n",
    "\n",
    "feature_list = list(df.corr().stress_index.to_frame().sort_values(by='stress_index', ascending=False).index)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892725, 0.745, 0.147725\n",
      "0.8913, 0.7512, 0.1401\n",
      "0.891725, 0.7452, 0.14652500000000002\n",
      "0.8917, 0.7486, 0.1431\n",
      "0.891475, 0.7549, 0.136575\n",
      "0.891525, 0.7496, 0.14192499999999997\n",
      "0.89125, 0.7476, 0.14364999999999994\n",
      "0.8917, 0.7495, 0.1422\n",
      "0.890725, 0.7554, 0.13532500000000003\n",
      "0.89315, 0.7461, 0.14705000000000001\n",
      "avg:\n",
      "0.8917275, 0.7493100000000001, 0.14241749999999992\n"
     ]
    }
   ],
   "source": [
    "def experiment_once(train, test, feature_list, depth=5, log=False):\n",
    "    x_train = train[feature_list]\n",
    "    x_test = test[feature_list]\n",
    "    y_train = train.stress_index\n",
    "    y_test = test.stress_index\n",
    "\n",
    "    clf = DecisionTreeClassifier(criterion = \"gini\", max_depth=depth, random_state=RANDOM_SEED)\n",
    "    dtree = clf.fit(x_train, y_train)\n",
    "    train_err = dtree.score(x_train, y_train)\n",
    "    test_err = dtree.score(x_test, y_test)\n",
    "    if log:\n",
    "        print(\"{}, {}, {}\".format(train_err, test_err, train_err - test_err))\n",
    "    return train_err, test_err\n",
    "\n",
    "def evalute(feature_list, times=10, depth=5, log=False):\n",
    "    total_train_err, total_test_err = 0, 0\n",
    "    for i in range(times):\n",
    "        train, test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED + i)\n",
    "        train_err, test_err = experiment_once(train, test, feature_list, depth, log)\n",
    "        total_train_err = total_train_err + train_err\n",
    "        total_test_err  = total_test_err  + test_err\n",
    "    print(\"avg:\")\n",
    "    print(\"{}, {}, {}\".format(total_train_err / times, total_test_err / times, (total_train_err - total_test_err) / times))\n",
    "\n",
    "evalute(feature_list[1:20], 10, depth=100, log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
