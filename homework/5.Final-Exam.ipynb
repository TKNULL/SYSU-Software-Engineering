{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam\n",
    "`jskyzero` `2018/07/18`\n",
    "\n",
    "## 分类算法介绍与分析\n",
    "\n",
    "以下主要介绍随机森林算法与神经网络算法。\n",
    "\n",
    "### 随机森林\n",
    "\n",
    "随机森林算法一个包含很多决策树的分类算法，并且通过决策树的“投票”来决定最后的结果。\n",
    "\n",
    "优点\n",
    "+ 在数据集上表现良好，相对其他算法有着很大的优势\n",
    "+ 它能够处理很高维度（feature很多）的数据，并且不用做特征选择\n",
    "+ 在训练完后，能够给出哪些feature比较重要\n",
    "+ 在创建随机森林的时候，对generlization error使用的是无偏估计\n",
    "+ 容易做成并行化方法,训练速度快\n",
    "+ 在训练过程中，能够检测到feature间的互相影响\n",
    "+ 实现比较简单\n",
    "\n",
    "缺点\n",
    "+ 已经被证明在某些噪音较大的分类或回归问题上会过拟合\n",
    "+ 对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的\n",
    "\n",
    "时间复杂度\n",
    "\n",
    "+ 假设 n 个样本，m个特征，一棵树的时间复杂度为O(mn logn).\n",
    "+ 假设用M个树来投票，时间复杂度为O(M(mn log n)).\n",
    "\n",
    "内存需求\n",
    "\n",
    "由于每棵树都需要储存，对内存需求极高（在本数据集的具体需求可以参考下方求解过程）\n",
    "\n",
    "### 神经网络\n",
    "\n",
    "模仿生物神经元对数据进行函数运算，可以使用大量神经元层级串联层层影响得到最后的结果。\n",
    "\n",
    "优点\n",
    "\n",
    "+ 有很强的非线性拟合能力，可映射任意复杂的非线性关系\n",
    "+ 学习规则和迭代规则简单，便于计算机实现\n",
    "+ 具有很强的鲁棒性、记忆能力、非线性映射能力以及强大的自学习能力\n",
    "\n",
    "缺点\n",
    "\n",
    "+ 没有特别直观的解释推理过程和推理依据的方法\n",
    "\n",
    "+ 当数据不充分的时候，效果相对较差\n",
    "\n",
    "+ 把数据完全理解为数字，将拟合过程变成纯数学问题，有丢失隐信息的风险\n",
    "\n",
    "\n",
    "时间复杂度\n",
    "\n",
    "假设为一个简单的三层BP神经网络，每层神经元数量分别为n1，n2，n3。（输入层和最终输出层结点数量(n1和n3)是确定）\n",
    "+ 前馈计算，两次矩阵乘法（实际上是向量和矩阵相乘）分别要进行n1 \\* n2 和 n2 \\* n3次计算，算时间复杂度是O(n1 \\* n2 + n2 \\* n3) = O(n2)。\n",
    "+ 反向传播时，假设总共有m个训练样本，每个样本只训练一次，时间复杂度应该是O(m*n2)。\n",
    "\n",
    "\n",
    "内存需求\n",
    "\n",
    "相较随机森林内存占用少了很多，主要是可以分次迭代每次只需要储存当次的数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求解过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理过程\n",
    "\n",
    "将数据处理为方便操作的形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import h5py\n",
    "import gc\n",
    "import shelve\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# set cofig\n",
    "FILE_PATH = \"D:\\\\Downloads\\\\\"\n",
    "SAMPLE_FILE_NAME = \"submission_sample.csv\"\n",
    "TRAIN_FILE_NAME = \"train_data.mat\"\n",
    "TEST_FILE_NAME = \"test_data_raw.mat\"\n",
    "OUT_FILE_NAME = \"out.csv\"\n",
    "SHELVE_FILE_NAME = \"shelve\"\n",
    "\n",
    "# read train file\n",
    "train_feat = h5py.File(FILE_PATH + TRAIN_FILE_NAME)['train_feat'][:]\n",
    "train_label = h5py.File(FILE_PATH + TRAIN_FILE_NAME)['train_label'][:]\n",
    "\n",
    "X = np.transpose(np.array(train_feat))\n",
    "Y = np.array(train_label)[0]\n",
    "\n",
    "print(\"X.shape = {}\".format(X.shape))\n",
    "print(\"Y.shape = {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可选的降维和数据清洗\n",
    "\n",
    "因为后面试过具体的降维的度比较难把握所以放弃进行降维，清洗同理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=1000)\n",
    "# pca.fit(X)\n",
    "# X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割数据集\n",
    "方便本地验证，如果需要最终提交的使用下面一个版本即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "\n",
    "# with shelve.open(FILE_PATH + SHELVE_FILE_NAME) as db:\n",
    "#     db['X_train'] = X_train\n",
    "#     db['X_test'] = X_test\n",
    "#     db['y_train'] = y_train\n",
    "#     db['y_test'] = y_test\n",
    "\n",
    "\n",
    "with shelve.open(FILE_PATH + SHELVE_FILE_NAME) as db:\n",
    "    db['X_train'] = X\n",
    "    db['X_test'] = \"\"\n",
    "    db['y_train'] = Y\n",
    "    db['y_test'] = \"\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再次读取数据\n",
    "\n",
    "因为前面预处理使用内存较大所以可以分步执行减低内存需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import h5py\n",
    "import gc\n",
    "import shelve\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# set cofig\n",
    "FILE_PATH = \"D:\\\\Downloads\\\\\"\n",
    "SAMPLE_FILE_NAME = \"submission_sample.csv\"\n",
    "TRAIN_FILE_NAME = \"train_data.mat\"\n",
    "TEST_FILE_NAME = \"test_data_raw.mat\"\n",
    "OUT_FILE_NAME = \"out.csv\"\n",
    "SHELVE_FILE_NAME = \"shelve\"\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "with shelve.open(FILE_PATH + SHELVE_FILE_NAME) as db:\n",
    "    X_train= db['X_train']\n",
    "    X_test = db['X_test']\n",
    "    y_train = db['y_train']\n",
    "    y_test = db['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林\n",
    "\n",
    "需要内存16G，I7 7700短期内可跑出，正确率大概0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(criterion=\"gini\",\n",
    "#                              max_features=20,\n",
    "# #                              max_depth=4,\n",
    "#                              n_estimators=140,\n",
    "#                              oob_score=True,\n",
    "#                              n_jobs=8,\n",
    "#                              random_state=0)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络\n",
    "\n",
    "相同配置，迭代大概需要数个小时，各种调整参数吼效果0.25+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "size = [1000]\n",
    "clf = MLPClassifier(hidden_layer_sizes=size,\n",
    "                    activation='tanh',\n",
    "                    solver='sgd',\n",
    "#                     alpha=0.0001,\n",
    "                    max_iter=100,\n",
    "                    verbose=True,\n",
    "#                     tol=0.001\n",
    "                   )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集效果\n",
    "可以观察是否过拟合，随即森林会出现较为明显的过拟合，多次迭代后升级网络在训练集也能达到1.0的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train error {}\".format(clf.score(X_train, y_train)))\n",
    "# print(\"test error {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交\n",
    "由于数据读取的问题，找个编辑器手动去掉浮点数的小数部分即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = h5py.File(FILE_PATH + TEST_FILE_NAME)['test_feat']\n",
    "test = np.transpose(np.array(test))\n",
    "print(\"test.shape = {}\".format(test.shape))\n",
    "test = scaler.transform(test) \n",
    "Y_test = clf.predict(test)\n",
    "sample_submission =  pd.read_csv(FILE_PATH + SAMPLE_FILE_NAME, sep=',')\n",
    "print(\"submisstion data shape = {}\".format(sample_submission.shape))\n",
    "sample_submission.iloc[:, 1:2] = Y_test\n",
    "sample_submission.to_csv(FILE_PATH + \"0\" + OUT_FILE_NAME, sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
