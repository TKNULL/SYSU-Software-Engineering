{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import h5py\n",
    "import gc\n",
    "import shelve\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# set cofig\n",
    "FILE_PATH = \"D:\\\\Downloads\\\\\"\n",
    "SAMPLE_FILE_NAME = \"submission_sample.csv\"\n",
    "TRAIN_FILE_NAME = \"train_data.mat\"\n",
    "TEST_FILE_NAME = \"test_data_raw.mat\"\n",
    "OUT_FILE_NAME = \"out.csv\"\n",
    "SHELVE_FILE_NAME = \"shelve\"\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "with shelve.open(FILE_PATH + SHELVE_FILE_NAME) as db:\n",
    "    X_train= db['X_train']\n",
    "    X_test = db['X_test']\n",
    "    y_train = db['y_train']\n",
    "    y_test = db['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.22980369\n",
      "Iteration 2, loss = 3.55614566\n",
      "Iteration 3, loss = 3.22381008\n",
      "Iteration 4, loss = 2.95699968\n",
      "Iteration 5, loss = 2.71409128\n",
      "Iteration 6, loss = 2.50386606\n",
      "Iteration 7, loss = 2.32831093\n",
      "Iteration 8, loss = 2.16411456\n",
      "Iteration 9, loss = 2.01132198\n",
      "Iteration 10, loss = 1.90075596\n",
      "Iteration 11, loss = 1.78793747\n",
      "Iteration 12, loss = 1.69954176\n",
      "Iteration 13, loss = 1.60420122\n",
      "Iteration 14, loss = 1.51895426\n",
      "Iteration 15, loss = 1.45904441\n",
      "Iteration 16, loss = 1.38038963\n",
      "Iteration 17, loss = 1.30521006\n",
      "Iteration 18, loss = 1.29163988\n",
      "Iteration 19, loss = 1.22551823\n",
      "Iteration 20, loss = 1.19623342\n",
      "Iteration 21, loss = 1.16567393\n",
      "Iteration 22, loss = 1.12311568\n",
      "Iteration 23, loss = 1.11486575\n",
      "Iteration 24, loss = 1.08380075\n",
      "Iteration 25, loss = 1.05952174\n",
      "Iteration 26, loss = 1.03629400\n",
      "Iteration 27, loss = 1.00358316\n",
      "Iteration 28, loss = 0.97906878\n",
      "Iteration 29, loss = 1.01443558\n",
      "Iteration 30, loss = 0.95183568\n",
      "Iteration 31, loss = 0.91482375\n",
      "Iteration 32, loss = 0.93424257\n",
      "Iteration 33, loss = 0.91468537\n",
      "Iteration 34, loss = 0.91545386\n",
      "Iteration 35, loss = 0.90763298\n",
      "Iteration 36, loss = 0.88797805\n",
      "Iteration 37, loss = 0.87909734\n",
      "Iteration 38, loss = 0.86016519\n",
      "Iteration 39, loss = 0.85445964\n",
      "Iteration 40, loss = 0.87164958\n",
      "Iteration 41, loss = 0.84846356\n",
      "Iteration 42, loss = 0.88441560\n",
      "Iteration 43, loss = 0.86998436\n",
      "Iteration 44, loss = 0.86516447\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[300, 300, 300, 300, 300, 300, 300, 300, 300, 300],\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-09,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(criterion=\"gini\",\n",
    "#                              max_features=20,\n",
    "# #                              max_depth=4,\n",
    "#                              n_estimators=140,\n",
    "#                              oob_score=True,\n",
    "#                              n_jobs=8,\n",
    "#                              random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "size = [300] * 10\n",
    "clf = MLPClassifier(hidden_layer_sizes=size,\n",
    "                    activation='tanh',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=500,\n",
    "                    verbose=True,\n",
    "                    tol=0.001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error 0.7914189110411566\n",
      "test error 0.19281217208814272\n"
     ]
    }
   ],
   "source": [
    "print(\"train error {}\".format(clf.score(X_train, y_train)))\n",
    "print(\"test error {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape = (19850, 6812)\n",
      "submisstion data shape = (19850, 2)\n"
     ]
    }
   ],
   "source": [
    "test = h5py.File(FILE_PATH + TEST_FILE_NAME)['test_feat']\n",
    "test = np.transpose(np.array(test))\n",
    "print(\"test.shape = {}\".format(test.shape))\n",
    "test = scaler.transform(test) \n",
    "Y_test = clf.predict(test)\n",
    "sample_submission =  pd.read_csv(FILE_PATH + SAMPLE_FILE_NAME, sep=',')\n",
    "print(\"submisstion data shape = {}\".format(sample_submission.shape))\n",
    "sample_submission.iloc[:, 1:2] = Y_test\n",
    "sample_submission.to_csv(FILE_PATH + \"0\" + OUT_FILE_NAME, sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
